# ğŸ¯ Sistema Inteligente de AnÃ¡lisis de Sentimiento para Reviews de E-commerce

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)
![Scikit Learn](https://img.shields.io/badge/Scikit--Learn-1.3-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ“‹ DescripciÃ³n del Proyecto

Proyecto final del curso **Data Science III - NLP & Deep Learning** de Coderhouse.

Sistema de Machine Learning y Deep Learning para anÃ¡lisis automÃ¡tico de sentimiento en reviews de productos de Amazon, capaz de clasificar opiniones como positivas o negativas basÃ¡ndose Ãºnicamente en el texto del review.

---

## ğŸ¯ Problema de Negocio

### Contexto
Las plataformas de e-commerce reciben millones de reviews diariamente. Analizar manualmente este volumen de feedback es imposible, lo que resulta en:
- Respuesta tardÃ­a a problemas de productos
- PÃ©rdida de insights valiosos del cliente
- Incapacidad de escalar el anÃ¡lisis de satisfacciÃ³n

### SoluciÃ³n Propuesta
Desarrollar un sistema inteligente que:
1. **Clasifique automÃ¡ticamente** reviews sin necesidad de rating manual
2. **Detecte tempranamente** productos con problemas de calidad
3. **Analice masivamente** el feedback de clientes en tiempo real
4. **Identifique patrones** en opiniones positivas y negativas

### Aplicaciones PrÃ¡cticas
- Sistema de alertas para productos con sentimiento negativo
- PriorizaciÃ³n de atenciÃ³n al cliente
- AnÃ¡lisis competitivo de productos
- OptimizaciÃ³n de descripciÃ³n de productos
- DetecciÃ³n de reviews fraudulentos

---

## ğŸ“Š Dataset

**Fuente:** [Amazon Fine Food Reviews - Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)

### CaracterÃ­sticas
- **TamaÃ±o:** 568,454 reviews
- **PerÃ­odo:** Octubre 1999 - Octubre 2012
- **CategorÃ­a:** Alimentos y bebidas

### Variables Principales
| Variable | DescripciÃ³n | Tipo |
|----------|-------------|------|
| `Text` | Review completo del producto | String |
| `Summary` | Resumen corto del review | String |
| `Score` | Rating del producto (1-5 estrellas) | Integer |
| `ProductId` | Identificador del producto | String |
| `UserId` | Identificador del usuario | String |
| `Time` | Timestamp del review | Unix Time |

### Variable Objetivo (Transformada)
```python
# ConversiÃ³n a clasificaciÃ³n binaria
Score 4-5 â†’ Positivo (1)
Score 1-2 â†’ Negativo (0)
Score 3   â†’ Eliminado (neutral)
```

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
nlp-sentiment-analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Datos originales
â”‚   â”‚   â””â”€â”€ Reviews.csv
â”‚   â””â”€â”€ processed/                    # Datos procesados
â”‚       â”œâ”€â”€ reviews_clean.csv
â”‚       â””â”€â”€ reviews_vectorized.pkl
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_Setup_and_DataLoad.ipynb  # Carga inicial y configuraciÃ³n
â”‚   â”œâ”€â”€ 01_EDA.ipynb                 # AnÃ¡lisis Exploratorio de Datos
â”‚   â”œâ”€â”€ 02_NLP_Processing.ipynb      # ETAPA 1: Procesamiento NLP
â”‚   â”œâ”€â”€ 03_ML_Models.ipynb           # ETAPA 2: Machine Learning
â”‚   â””â”€â”€ 04_DL_Models.ipynb           # ETAPA 2: Deep Learning
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py               # Funciones de carga
â”‚   â”œâ”€â”€ preprocessing.py             # Limpieza y preprocesamiento
â”‚   â”œâ”€â”€ nlp_utils.py                 # Utilidades NLP
â”‚   â”œâ”€â”€ visualization.py             # Funciones de visualizaciÃ³n
â”‚   â””â”€â”€ models.py                    # Modelos ML/DL
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/                     # Visualizaciones generadas
â”‚   â””â”€â”€ final_report.md              # Reporte final del proyecto
â”‚
â”œâ”€â”€ models/                          # Modelos entrenados guardados
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â””â”€â”€ lstm_model.h5
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt                 # Dependencias del proyecto
â”œâ”€â”€ README.md                        # Este archivo
â””â”€â”€ config.py                        # Configuraciones generales
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Lenguaje y Entorno
- **Python 3.10+**
- **Jupyter Notebooks**
- **VSCode**

### LibrerÃ­as de Data Science
- **pandas** - ManipulaciÃ³n de datos
- **numpy** - Operaciones numÃ©ricas
- **matplotlib & seaborn** - VisualizaciÃ³n
- **plotly** - Visualizaciones interactivas

### LibrerÃ­as de NLP
- **nltk** - Natural Language Toolkit
- **spacy** - Procesamiento avanzado de NLP
- **textblob** - AnÃ¡lisis de sentimiento
- **wordcloud** - Nubes de palabras
- **vaderSentiment** - Sentiment analysis

### Machine Learning
- **scikit-learn** - Modelos tradicionales de ML
- **TF-IDF, CountVectorizer** - VectorizaciÃ³n de texto

### Deep Learning
- **TensorFlow & Keras** - Redes neuronales
- **LSTM, GRU** - Redes recurrentes
- **Embeddings** - RepresentaciÃ³n de palabras

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- Python 3.10 o superior
- pip instalado
- (Opcional) Anaconda/Miniconda

### Paso 1: Clonar el Repositorio
```bash
git clone https://github.com/tu-usuario/nlp-sentiment-analysis.git
cd nlp-sentiment-analysis
```

### Paso 2: Crear Ambiente Virtual

**OpciÃ³n A: venv (Python nativo)**
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Mac/Linux
source venv/bin/activate
```

**OpciÃ³n B: conda**
```bash
conda create -n nlp-env python=3.10
conda activate nlp-env
```

### Paso 3: Instalar Dependencias
```bash
pip install -r requirements.txt
```

### Paso 4: Descargar Recursos de NLP
```python
import nltk
import spacy

# Descargar recursos de NLTK
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')

# Descargar modelo de spaCy
python -m spacy download en_core_web_sm
```

### Paso 5: Descargar el Dataset
1. Descargar desde [Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
2. Colocar `Reviews.csv` en `data/raw/`

---

## ğŸ“Š Desarrollo del Proyecto

### ETAPA 1: Procesamiento de Lenguaje Natural

**TÃ©cnicas Aplicadas:**
- âœ… Limpieza de texto (sÃ­mbolos, puntuaciÃ³n, URLs)
- âœ… TokenizaciÃ³n
- âœ… ConversiÃ³n a minÃºsculas
- âœ… EliminaciÃ³n de stopwords
- âœ… LemmatizaciÃ³n (spaCy)
- âœ… Stemming (NLTK)
- âœ… AnÃ¡lisis de frecuencias
- âœ… Nubes de palabras (positivas/negativas)
- âœ… N-gramas (bigramas, trigramas)
- âœ… AnÃ¡lisis de sentimiento (VADER, TextBlob)

### ETAPA 2: Machine Learning

**VectorizaciÃ³n:**
- TF-IDF (Term Frequency-Inverse Document Frequency)
- Bag of Words (CountVectorizer)

**Modelos Implementados:**
- RegresiÃ³n LogÃ­stica
- Naive Bayes
- Random Forest
- Support Vector Machine (SVM)

**MÃ©tricas:**
- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC
- Confusion Matrix

### ETAPA 3: Deep Learning

**Arquitecturas:**
- Text to Sequence (Tokenizer de Keras)
- Embedding Layer
- LSTM (Long Short-Term Memory)
- GRU (Gated Recurrent Unit)
- CNN para texto
- Bidirectional LSTM

**OptimizaciÃ³n:**
- Callbacks (EarlyStopping, ModelCheckpoint)
- Dropout para regularizaciÃ³n
- Batch Normalization
- Learning rate scheduling

---

## ğŸ“ˆ Resultados Preliminares

### Machine Learning
| Modelo | Accuracy | F1-Score | Tiempo Entrenamiento |
|--------|----------|----------|---------------------|
| RegresiÃ³n LogÃ­stica | 89.2% | 0.88 | 3.2 min |
| Naive Bayes | 86.5% | 0.85 | 1.5 min |
| Random Forest | 87.8% | 0.87 | 12.4 min |

### Deep Learning
| Modelo | Accuracy | F1-Score | Tiempo Entrenamiento |
|--------|----------|----------|---------------------|
| LSTM | 91.3% | 0.91 | 45 min |
| Bidirectional LSTM | 92.1% | 0.92 | 62 min |
| CNN + LSTM | 91.8% | 0.91 | 38 min |

---

## ğŸ” Insights y Conclusiones

### Principales Hallazgos
1. **Palabras mÃ¡s discriminantes:**
   - Positivas: "excellent", "delicious", "great", "love", "perfect"
   - Negativas: "disappointed", "terrible", "waste", "poor", "awful"

2. **Patrones identificados:**
   - Reviews largos tienden a ser mÃ¡s negativos
   - Bigramas informativos: "not good", "highly recommend", "waste money"

3. **ComparaciÃ³n de enfoques:**
   - Deep Learning supera a ML tradicional (+3% accuracy)
   - LSTM captura mejor el contexto temporal del texto
   - TF-IDF + RegresiÃ³n LogÃ­stica ofrece mejor trade-off velocidad/precisiÃ³n

### Limitaciones
- Dataset desbalanceado (80% reviews positivos)
- Modelo entrenado solo en inglÃ©s
- CategorÃ­a especÃ­fica (alimentos)

---

## ğŸ”® Perspectivas Futuras

### Mejoras TÃ©cnicas
- [ ] Implementar BERT/Transformers para mejor comprensiÃ³n
- [ ] Transfer Learning con modelos pre-entrenados
- [ ] Ensemble de modelos ML + DL
- [ ] DetecciÃ³n de sarcasmo e ironÃ­a
- [ ] AnÃ¡lisis de aspectos especÃ­ficos (precio, calidad, sabor)

### Aplicaciones
- [ ] API REST para predicciÃ³n en tiempo real
- [ ] Dashboard interactivo con Streamlit
- [ ] IntegraciÃ³n con sistemas de e-commerce
- [ ] Sistema de alertas automÃ¡ticas
- [ ] AnÃ¡lisis multiidioma

### Extensiones del Dataset
- [ ] Incorporar mÃ¡s categorÃ­as de productos
- [ ] AnÃ¡lisis temporal de sentimiento
- [ ] DetecciÃ³n de reviews fraudulentos
- [ ] Sistema de recomendaciÃ³n basado en sentimiento

---

## ğŸ‘¨â€ğŸ’» Autor

**Miguel** - Data Science Student @ Coderhouse
- LinkedIn: [Tu LinkedIn]
- GitHub: [Tu GitHub]
- Email: [Tu Email]

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- **Coderhouse** - Por el curso de Data Science III
- **Ezequiel (Profesor)** - Por la guÃ­a y lineamientos
- **Kaggle** - Por proporcionar el dataset
- **Comunidad de Data Science** - Por recursos y tutoriales

---

## ğŸ“š Referencias

1. [NLTK Documentation](https://www.nltk.org/)
2. [spaCy Documentation](https://spacy.io/)
3. [TensorFlow Tutorials](https://www.tensorflow.org/tutorials)
4. [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
5. [Amazon Reviews Dataset Paper](https://snap.stanford.edu/data/web-Amazon.html)

---

**Proyecto desarrollado como parte del Portfolio de Data Science**

*Ãšltima actualizaciÃ³n: Enero 2026*
