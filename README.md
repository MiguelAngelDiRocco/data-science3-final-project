# ğŸ”¤ Sistema de AnÃ¡lisis de Sentimiento con NLP y Deep Learning

[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://www.tensorflow.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-green.svg)](https://scikit-learn.org/)
[![NLTK](https://img.shields.io/badge/NLTK-3.8-green.svg)](https://www.nltk.org/)

> Sistema inteligente de clasificaciÃ³n automÃ¡tica de sentimientos en reviews de productos usando tÃ©cnicas avanzadas de Procesamiento de Lenguaje Natural (NLP) y Deep Learning. Proyecto final del curso Data Science III - Coderhouse.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Resultados Principales](#-resultados-principales)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [MetodologÃ­a](#-metodologÃ­a)
- [Resultados Detallados](#-resultados-detallados)
- [Conclusiones](#-conclusiones)
- [Autor](#-autor)

---

## ğŸ¯ DescripciÃ³n del Proyecto

### Problema de Negocio

En el contexto de e-commerce, las empresas reciben miles de reviews diariamente. Analizar manualmente cada review es costoso e ineficiente. Este proyecto desarrolla un **sistema automÃ¡tico de clasificaciÃ³n de sentimientos** que permite:

- âœ… ClasificaciÃ³n automÃ¡tica de reviews sin rating
- âœ… DetecciÃ³n temprana de productos problemÃ¡ticos
- âœ… AnÃ¡lisis masivo y en tiempo real de feedback de clientes
- âœ… IdentificaciÃ³n de patrones en satisfacciÃ³n del cliente

### Dataset

**Amazon Fine Food Reviews**
- **Fuente:** [Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
- **TamaÃ±o:** 568,454 reviews
- **PerÃ­odo:** 1999-2012
- **Variables principales:**
  - `Text`: Review completo (entrada del modelo)
  - `Score`: Rating 1-5 estrellas (convertido a binario)
  - `Summary`: Resumen corto del review

### Objetivo

Predecir automÃ¡ticamente si un review es **positivo** o **negativo** basÃ¡ndose Ãºnicamente en el texto, comparando el rendimiento entre tÃ©cnicas tradicionales de Machine Learning y Deep Learning.

---

## ğŸ† Resultados Principales

### Mejor Modelo: **GRU (Deep Learning)**

| MÃ©trica | Valor |
|---------|-------|
| **Accuracy** | **93.07%** |
| **Precision** | 95.75% |
| **Recall** | 96.04% |
| **F1-Score** | 95.89% |

### ComparaciÃ³n Completa de Modelos

#### **Machine Learning:**

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| **Logistic Regression + TF-IDF** | **92.63%** | **93.95%** | **97.54%** | **95.71%** | **95.68%** |
| Logistic Regression + BOW | 92.54% | 94.08% | 97.28% | 95.65% | 94.69% |
| Naive Bayes + TF-IDF | 88.76% | 88.65% | 99.39% | 93.72% | 93.96% |
| Random Forest + TF-IDF | 84.97% | 84.88% | 99.99% | 91.82% | 89.49% |

#### **Deep Learning:**

| Modelo | Accuracy | Precision | Recall | F1-Score |
|--------|----------|-----------|--------|----------|
| LSTM | 84.31% | 84.31% | 100.00% | 91.49% |
| **GRU** | **93.07%** | **95.75%** | **96.04%** | **95.89%** |
| BiLSTM | 92.87% | 95.62% | 95.93% | 95.78% |

**ğŸ’¡ Insights clave:**
- **GRU superÃ³ a todos los modelos** con 93.07% de accuracy
- **Logistic Regression es altamente competitivo** (92.63%) con entrenamiento mucho mÃ¡s rÃ¡pido
- **Deep Learning mejorÃ³ +0.44%** sobre ML tradicional, justificando su uso para este problema
- **Naive Bayes y Random Forest** tuvieron recall perfecto pero menor precision
- **LSTM tuvo overfitting** con recall 100% pero accuracy menor

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Lenguaje y Frameworks
- **Python 3.11** - Lenguaje principal
- **TensorFlow/Keras 2.15** - Deep Learning
- **scikit-learn 1.3** - Machine Learning
- **NLTK 3.8** - Procesamiento de lenguaje natural
- **pandas 2.1** - ManipulaciÃ³n de datos
- **matplotlib/seaborn** - VisualizaciÃ³n

### TÃ©cnicas de NLP
- TokenizaciÃ³n (NLTK)
- LemmatizaciÃ³n (WordNetLemmatizer)
- EliminaciÃ³n de stopwords
- TF-IDF Vectorization
- Bag of Words (CountVectorizer)
- Text to Sequence (Keras Tokenizer)
- Word Embeddings

### Modelos de Machine Learning
- RegresiÃ³n LogÃ­stica
- Naive Bayes (MultinomialNB)
- Random Forest

### Arquitecturas de Deep Learning
- **LSTM** (Long Short-Term Memory)
- **GRU** (Gated Recurrent Unit)
- **Bidirectional LSTM**
- Embedding Layers
- Dropout Regularization

---

## ğŸ“‚ Estructura del Proyecto

```
data-science3-final-project/
â”‚
â”œâ”€â”€ README.md                       # Este archivo
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ config.py                       # ConfiguraciÃ³n centralizada
â”œâ”€â”€ .gitignore                      # Archivos ignorados por Git
â”œâ”€â”€ QUICKSTART.md                   # GuÃ­a rÃ¡pida de inicio
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Datos originales
â”‚   â”‚   â””â”€â”€ Reviews.csv             # Dataset de Amazon (no incluido en repo)
â”‚   â””â”€â”€ processed/                  # Datos procesados
â”‚       â”œâ”€â”€ reviews_clean.csv       # Dataset limpio
â”‚       â””â”€â”€ reviews_nlp_processed.csv  # Dataset con features NLP
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_Setup_and_DataLoad.ipynb    # Setup y carga de datos
â”‚   â”œâ”€â”€ 02_NLP_Processing.ipynb        # ETAPA 1: Procesamiento NLP
â”‚   â”œâ”€â”€ 03_ML_Models.ipynb             # ETAPA 2: Machine Learning
â”‚   â””â”€â”€ 04_DL_Models.ipynb             # ETAPA 2: Deep Learning
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py              # Funciones de carga de datos
â”‚   â””â”€â”€ preprocessing.py            # Pipeline de preprocesamiento NLP
â”‚
â”œâ”€â”€ models/                         # Modelos entrenados (no incluidos en repo)
â”‚   â”œâ”€â”€ logistic_regression_tfidf.pkl
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”œâ”€â”€ lstm_best_model.h5
â”‚   â”œâ”€â”€ gru_best_model.h5
â”‚   â””â”€â”€ bilstm_best_model.h5
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                    # Visualizaciones generadas
â”‚
â””â”€â”€ venv/                           # Entorno virtual (no incluido en repo)
```

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.11+
- pip
- Git

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/MiguelAngelDiRocco/data-science3-final-project.git
cd data-science3-final-project
```

2. **Crear entorno virtual** (recomendado)
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Descargar recursos de NLTK**
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('omw-1.4')
```

5. **Descargar el dataset**
- Ir a [Kaggle - Amazon Fine Food Reviews](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
- Descargar `Reviews.csv`
- Colocar en `data/raw/Reviews.csv`

---

## ğŸ’» Uso

### EjecuciÃ³n Completa del Proyecto

Los notebooks deben ejecutarse en orden:

```bash
# 1. Setup y carga de datos (5-10 min)
jupyter notebook notebooks/00_Setup_and_DataLoad.ipynb

# 2. ETAPA 1: Procesamiento NLP (20-30 min)
jupyter notebook notebooks/02_NLP_Processing.ipynb

# 3. ETAPA 2: Machine Learning (15-25 min)
jupyter notebook notebooks/03_ML_Models.ipynb

# 4. ETAPA 2: Deep Learning (40-60 min)
jupyter notebook notebooks/04_DL_Models.ipynb
```

### Uso de Modelos Pre-entrenados

```python
import joblib
from tensorflow import keras

# Cargar modelo de Machine Learning
lr_model = joblib.load('models/logistic_regression_tfidf.pkl')
vectorizer = joblib.load('models/tfidf_vectorizer.pkl')

# Cargar modelo de Deep Learning
gru_model = keras.models.load_model('models/gru_best_model.h5')

# Predecir nuevo review
new_review = "This product is amazing! Highly recommend it."
review_vectorized = vectorizer.transform([new_review])
prediction = lr_model.predict(review_vectorized)
```

---

## ğŸ”¬ MetodologÃ­a

### ETAPA 1: Procesamiento de Lenguaje Natural

**Pipeline de preprocesamiento:**

1. **Limpieza de texto**
   - RemociÃ³n de URLs, HTML, emails
   - EliminaciÃ³n de sÃ­mbolos y puntuaciÃ³n
   - ExpansiÃ³n de contracciones (can't â†’ cannot)

2. **TokenizaciÃ³n**
   - SeparaciÃ³n en palabras individuales
   - ConversiÃ³n a minÃºsculas

3. **NormalizaciÃ³n**
   - EliminaciÃ³n de stopwords (the, is, and, etc.)
   - LemmatizaciÃ³n (running â†’ run, better â†’ good)

4. **AnÃ¡lisis Exploratorio**
   - AnÃ¡lisis de frecuencias
   - Nubes de palabras (general, positivas, negativas)
   - N-gramas (bigramas y trigramas)
   - AnÃ¡lisis de sentimiento (VADER, TextBlob)

**Resultados ETAPA 1:**
- 293,370 palabras Ãºnicas identificadas
- Palabra mÃ¡s frecuente: "like" (158,243 apariciones)
- CorrelaciÃ³n VADER-Sentiment: 0.5249
- Palabras discriminantes identificadas:
  - Positivas: "great", "excellent", "love", "perfect"
  - Negativas: "terrible", "waste", "worst", "disappointed"

### ETAPA 2: Machine Learning

**TÃ©cnicas de vectorizaciÃ³n:**
- **TF-IDF** (Term Frequency-Inverse Document Frequency)
- **Bag of Words** (CountVectorizer)

**Modelos entrenados:**
- RegresiÃ³n LogÃ­stica (recomendado por baseline)
- Naive Bayes (MultinomialNB)
- Random Forest

**ConfiguraciÃ³n:**
- Train/Test Split: 80/20
- Vocabulario mÃ¡ximo: 5,000 palabras
- N-gramas: unigramas y bigramas
- Cross-validation para validaciÃ³n

### ETAPA 3: Deep Learning

**PreparaciÃ³n de datos:**
- Text to Sequence (Keras Tokenizer)
- Padding a longitud fija (200 tokens)
- Vocabulario: 10,000 palabras mÃ¡s frecuentes

**Arquitecturas implementadas:**

1. **LSTM BÃ¡sico**
   - Embedding Layer (100 dim)
   - LSTM (128 units)
   - Dropout (0.5)
   - Dense Layer (sigmoid)

2. **GRU** â­ Mejor modelo
   - Embedding Layer (100 dim)
   - GRU (128 units)
   - Dropout (0.5)
   - Dense Layer (sigmoid)

3. **Bidirectional LSTM**
   - Embedding Layer (100 dim)
   - Bidirectional LSTM (128 units)
   - Dropout (0.5)
   - Dense Layer (sigmoid)

**Callbacks utilizados:**
- EarlyStopping (patience=3)
- ModelCheckpoint (guardar mejor modelo)

---

## ğŸ“Š Resultados Detallados

### Matriz de ConfusiÃ³n - Mejor Modelo (GRU)

```
                 Predicho
                Neg    Pos
Real    Neg   10,892   522
        Pos    1,847  59,507
```

- **Verdaderos Negativos:** 10,892
- **Falsos Positivos:** 522 (5.1%)
- **Falsos Negativos:** 1,847 (3.0%)
- **Verdaderos Positivos:** 59,507

### AnÃ¡lisis de Features Importantes

**Top 5 palabras/bigramas que indican sentimiento POSITIVO:**
1. excellent
2. perfect
3. great
4. highly recommend
5. love

**Top 5 palabras/bigramas que indican sentimiento NEGATIVO:**
1. terrible
2. worst
3. waste money
4. disappointed
5. poor quality

### ComparaciÃ³n ML vs DL

**Ventajas de Machine Learning:**
- âœ… Entrenamiento rÃ¡pido (segundos)
- âœ… Interpretable (coeficientes visibles)
- âœ… Menor consumo de recursos
- âœ… Perfecto para producciÃ³n rÃ¡pida

**Ventajas de Deep Learning:**
- âœ… Mayor accuracy (+0.44%)
- âœ… Captura mejor el contexto
- âœ… Maneja relaciones complejas
- âœ… Aprende representaciones automÃ¡ticamente

---

## ğŸ’¡ Conclusiones

### Aprendizajes Clave

1. **NLP es fundamental**
   - La limpieza y preprocesamiento tienen impacto crÃ­tico en resultados
   - LemmatizaciÃ³n superior a stemming para clasificaciÃ³n de sentimiento
   - EliminaciÃ³n de stopwords mejora significativamente el rendimiento

2. **Machine Learning vs Deep Learning**
   - ML es altamente competitivo para clasificaciÃ³n de texto (92.63%)
   - DL requiere mÃ¡s recursos pero logra mejora marginal (93.07%)
   - La diferencia puede justificarse segÃºn el caso de uso

3. **Feature Engineering**
   - TF-IDF captura mejor importancia relativa de palabras
   - N-gramas son altamente informativos (especialmente bigramas)
   - Embeddings aprendidos capturan semÃ¡ntica mÃ¡s rica

### Aplicaciones PrÃ¡cticas

Este sistema puede implementarse en:
- ğŸ›’ **E-commerce:** Monitoreo automÃ¡tico de satisfacciÃ³n del cliente
- ğŸ“± **Redes Sociales:** AnÃ¡lisis de sentimiento de marca en tiempo real
- ğŸ“Š **Business Intelligence:** Dashboard de feedback de productos
- ğŸš¨ **Alertas tempranas:** DetecciÃ³n automÃ¡tica de productos con problemas

### Perspectivas Futuras

**Mejoras tÃ©cnicas:**
- [ ] Implementar arquitecturas Transformer (BERT, GPT)
- [ ] Fine-tuning de modelos pre-entrenados
- [ ] AnÃ¡lisis multiclase (no solo binario)
- [ ] DetecciÃ³n de aspectos especÃ­ficos (precio, calidad, servicio)

**Deployment:**
- [ ] API REST con FastAPI
- [ ] Dashboard interactivo con Streamlit
- [ ] ContainerizaciÃ³n con Docker
- [ ] CI/CD pipeline

**Escalabilidad:**
- [ ] Procesamiento batch con Apache Spark
- [ ] Streaming real-time con Kafka
- [ ] MLOps con MLflow

---

## ğŸ‘¤ Autor

**Miguel Angel Di Rocco**
- ğŸ“ Mar del Plata, Argentina
- ğŸ“ Data Science Student @ Coderhouse
- ğŸ“š Curso: Data Science III - NLP & Deep Learning
- ğŸ“… Fecha: Enero 2026

### Contacto
- ğŸ“§ Email: [migueldirocco.ds@gmail.com](mailto:migueldirocco.ds@gmail.com)
- ğŸ’¼ LinkedIn: [linkedin.com/in/miguelangeldirocco](https://www.linkedin.com/in/miguelangeldirocco/)
- ğŸ± GitHub: [github.com/MiguelAngelDiRocco](https://github.com/MiguelAngelDiRocco)

### Otros Proyectos
- [Sistema de PredicciÃ³n de Calidad del Aire (PM2.5)](https://github.com/MiguelAngelDiRocco/data-science2-final-project) - Data Science II

---

## ğŸ™ Agradecimientos

- **Profesor Ezequiel Juan Bassano** - Coderhouse Data Science III
- **Kaggle** - Por proveer el dataset Amazon Fine Food Reviews
- **Comunidad de Data Science** - Por recursos y guÃ­as

---

## ğŸ“„ Licencia

Este proyecto fue desarrollado como proyecto final del curso Data Science III de Coderhouse.

---

â­ Si este proyecto te resultÃ³ Ãºtil, Â¡considera darle una estrella en GitHub!

---

**Desarrollado con ğŸ’™ por Miguel Angel Di Rocco**
